// baseURL/api/openai (back-end setup)
import { NextResponse } from "next/server";
import { OpenAIApi, Configuration, CreateChatCompletionResponse } from "openai";
import { AxiosResponse } from "axios";

const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
});
const openai = new OpenAIApi(configuration);

export async function POST(request: Request, response: any) {
  try {
    const { title, role } = await request.json(); // if we're sending information from the front-end in the body object, await request.json() is how we grab the information from the request

    const aiResponse: AxiosResponse<CreateChatCompletionResponse, any> =
      await openai.createChatCompletion({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "user",
            // content: `Create small blog post with html tags based on this title: ${title}`,
            content: `Create 3 line blog post with html tags based on this title: ${title}`,
          },
          {
            role: "system",
            content: `${
              role || "I am a helpful assistant"
            }. Write with html tags.`,
          },
        ],
      });
    // console.log("aiResponse.data.choices[0]: ", aiResponse.data.choices[0]);

    // response.revalidate("/api/posts") // get an updated version of all the posts, but vercel has time limit, so it's not going to work

    return NextResponse.json(
      {
        content: aiResponse.data.choices[0].message?.content,
      },
      { status: 200 }
    );
  } catch (error) {
    console.error("request error", error);
    NextResponse.json({ error: "error updating post" }, { status: 500 });
  }
}
